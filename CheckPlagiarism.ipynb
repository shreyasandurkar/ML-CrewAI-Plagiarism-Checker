{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook requires the following:\n",
    "# Install ollama https://ollama.com/docs/installation\n",
    "# \"ollama pull llama3.1:latest\"\n",
    "# pip install crewai\n",
    "\n",
    "# The input text file should be placed in ./input/article.txt\n",
    "# The output report will be saved in ./output/plagiarism_report.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import Libraries and Set Up Environment\n",
    "import os\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai import LLM\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ['CREWAI_API_URL'] = 'http://localhost:11434'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import LLM\n",
    "import re\n",
    "\n",
    "# Initialize the local LLM\n",
    "llm = LLM(\n",
    "    model=\"ollama/llama3.1:latest\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    provider=\"ollama\",\n",
    "    temperature=0.3,\n",
    "    timeout=180000\n",
    ")\n",
    "\n",
    "def read_article(file_path):\n",
    "    \"\"\"Read the article text from a file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return None\n",
    "\n",
    "def split_into_chunks(text, chunk_size=1000):\n",
    "    \"\"\"Split text into smaller chunks for processing.\"\"\"\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "def analyze_chunk(chunk):\n",
    "    \"\"\"Analyze a single chunk for plagiarism using LLM.\"\"\"\n",
    "    prompt = f\"\"\"Analyze this text for plagiarism risk. Provide:\n",
    "    1. Score: 0-100 (0=original, 100=plagiarized)\n",
    "    2. Brief explanation\n",
    "    Format exactly as:\n",
    "    Score: [number]\n",
    "    Explanation: [text]\n",
    "\n",
    "    Text: {chunk}\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.call(prompt)\n",
    "        score_match = re.search(r\"Score:\\s*(\\d+)\", response)\n",
    "        explanation_match = re.search(r\"Explanation:\\s*(.+)\", response, re.DOTALL)\n",
    "        \n",
    "        return {\n",
    "            \"score\": min(100, max(0, int(score_match.group(1))) if score_match else 0),\n",
    "            \"explanation\": explanation_match.group(1).strip() if explanation_match else \"No explanation provided\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing chunk: {e}\")\n",
    "        return {\"score\": 0, \"explanation\": \"Analysis failed\"}\n",
    "\n",
    "def generate_report(results):\n",
    "    \"\"\"Generate final report using LLM.\"\"\"\n",
    "    high_risk = [r for r in results if r[\"score\"] > 50]\n",
    "    num_high_risk = len(high_risk)\n",
    "    avg_score = sum(r[\"score\"] for r in results) / len(results) if results else 0\n",
    "        \n",
    "    report_prompt = f\"\"\"Create a plagiarism report with:\n",
    "    1. Brief summary of findings\n",
    "    2. High-risk chunk statistics\n",
    "    3. Recommendations\n",
    "    4. High-risk chunk texts\n",
    "\n",
    "    Data:\n",
    "    - Total chunks: {len(results)}\n",
    "    - High-risk chunks: {num_high_risk}\n",
    "    - Average score: {avg_score:.1f}\n",
    "    - Highest score: {max(r[\"score\"] for r in results) if results else 0}\n",
    "    \"\"\"\n",
    "    \n",
    "    return llm.call(report_prompt)\n",
    "\n",
    "def save_results(content, output_file):\n",
    "    \"\"\"Save results to a file.\"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(content)\n",
    "\n",
    "# Main processing\n",
    "if __name__ == \"__main__\":\n",
    "    # Read and chunk the article\n",
    "    article_text = read_article(\"./input/article.txt\")\n",
    "    if not article_text:\n",
    "        exit(1)\n",
    "        \n",
    "    chunks = split_into_chunks(article_text)\n",
    "    \n",
    "    # Analyze chunks\n",
    "    results = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Analyzing chunk {i+1}/{len(chunks)}...\")\n",
    "        analysis = analyze_chunk(chunk)\n",
    "        results.append({\n",
    "            \"chunk_number\": i+1,\n",
    "            \"score\": analysis[\"score\"],\n",
    "            \"explanation\": analysis[\"explanation\"]\n",
    "        })\n",
    "    \n",
    "    # Generate and save report\n",
    "    final_report = generate_report(results)\n",
    "    save_results(final_report, \"./output/plagiarism_report.txt\")\n",
    "    \n",
    "    # Print high-risk chunks\n",
    "    high_risk = [r for r in results if r[\"score\"] > 50]\n",
    "    num_high_risk = len(high_risk)\n",
    "    high_risk_texts = \"\\n\\n\".join([f\"Chunk {r['chunk_number']}:\\n\\n{chunks[r['chunk_number']-1]}\" for r in high_risk])\n",
    "    with open(\"./output/plagiarism_report.txt\", 'a', encoding='utf-8') as file:\n",
    "        file.write(f\"\\nHigh-risk chunk texts: {high_risk_texts}\")\n",
    "    \n",
    "    print(\"\\nPlagiarism analysis complete. Results saved to ./output/plagiarism_report.txt\")\n",
    "    \n",
    "    print(\"\\nHigh-risk chunks:\")\n",
    "    for r in high_risk:\n",
    "        print(f\"Chunk {r['chunk_number']}: Score {r['score']} - {r['explanation']}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
